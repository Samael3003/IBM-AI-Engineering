## Question 1
**Which one is TRUE about the kNN algorithm?**

- [ ] kNN calculates similarity by measuring how close the two data points’ response values are.
- [ ] kNN is a classification algorithm that takes a bunch of unlabelled points and uses them to learn how to label other points.
- [ ] The most similar point in kNN is the one with the smallest distance averaged across all normalized features.
- [ ] kNN algorithm can be used to estimate values for a continuous target.

---

## Question 2
**If the information gain of the tree by using attribute A is 0.3, what can we infer?**

- [ ] Entropy in the decision tree increases by 0.3 if we make this split.
- [ ] By making this split, we increase the randomness in each child node by 0.3.
- [ ] The entropy of a tree before split minus weighted entropy after split by attribute A is 0.3.
- [ ] Compared to attribute B with 0.65 information gain, attribute A should be selected first for splitting.

---

## Question 3
**When we have a value of K for KNN that’s too small, what will the model most likely look like?**

- [ ] The model will be overly simple and does not capture enough noise.
- [ ] The model will have high out-of-sample accuracy.
- [ ] The model will be highly complex and captures too much noise.
- [ ] The model will have high accuracy on the test set.
