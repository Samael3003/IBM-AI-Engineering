# Logistic Regression

### **Introduction to Logistic Regression**
- **Logistic Regression** is a statistical and machine learning method used for **classification** tasks.
- It is similar to linear regression but is used to predict a **categorical** (discrete) target variable rather than a continuous one.

### **Applications of Logistic Regression**
- **Binary Classification:** Predicting whether an event will happen or not (e.g., customer churn, disease diagnosis, etc.).
- **Multi-class Classification:** Logistic regression can be extended for multi-class classification, but this lecture focuses on binary classification.

### **Understanding Logistic Regression**
- Logistic regression models the probability that a given input point belongs to a certain class.
- **Independent Variables:** Continuous variables used as predictors (e.g., age, income).
- **Dependent Variable:** The binary target variable (e.g., churn: yes/no).

### **Comparison with Linear Regression**
- **Linear Regression:** Used to predict a continuous outcome (e.g., house prices, patientâ€™s blood pressure).
- **Logistic Regression:** Predicts a binary outcome (e.g., whether a customer will churn or not).
- Linear regression is not suitable for classification as it may produce values outside the [0, 1] range. Logistic regression addresses this by predicting probabilities.

### **Sigmoid Function**
- The key to logistic regression is the **sigmoid function**:
  \[
  \text{Sigmoid}(z) = \frac{1}{1 + e^{-z}}
  \]
- **Output Range:** The sigmoid function outputs values between 0 and 1, which represent probabilities.
- The sigmoid function is used to map the output of the linear equation to a probability.

### **Decision Boundary**
- **Linear Decision Boundary:** The decision boundary is linear in logistic regression, classifying points based on whether the predicted probability is above or below a threshold (usually 0.5).
- The decision boundary separates the classes, with points on one side classified as one class and those on the other side as the other class.

### **Training the Model**
1. **Initialize Parameters:** Start with random values for the parameters (weights).
2. **Model Output Calculation:** Use the sigmoid function to calculate the probability that a sample belongs to a certain class.
3. **Optimization:** The parameters are adjusted iteratively to minimize the error between the predicted and actual class labels (using a method such as Gradient Descent).

### **Why Use Logistic Regression?**
- **Probabilistic Interpretation:** Logistic regression gives the probability of an instance belonging to a class, which is useful in many practical applications.
- **Feature Importance:** The coefficients (weights) in logistic regression can be used to understand the importance of each feature.

### **Limitations**
- **Linear Separability:** Logistic regression assumes that the data is linearly separable. For more complex relationships, other methods (e.g., polynomial logistic regression or non-linear classifiers) may be needed.
- **Interpretability:** While the model is interpretable, it may not capture all the nuances in complex data.

### **Key Takeaways**
- Logistic regression is a powerful yet simple tool for binary classification problems.
- It is useful when the outcome is categorical and when understanding the probability of an event is important.
- The sigmoid function is central to the model, ensuring that predictions are always within the [0, 1] range.
