# Neural Networks and Gradient Descent - Lecture Notes

## Table of Contents

1. [Introduction to Gradient Descent](#introduction-to-gradient-descent)
2. [Gradient Descent Algorithm](#gradient-descent-algorithm)
3. [Forward Propagation and Error Calculation](#forward-propagation-and-error-calculation)
4. [Backpropagation](#backpropagation)
5. [Vanishing Gradient Problem](#vanishing-gradient-problem)
6. [Activation Functions](#activation-functions)

---

## 1. Introduction to Gradient Descent

### Overview
Gradient Descent is an iterative optimization algorithm used to minimize the cost or loss function in machine learning models. The goal is to find the optimal parameters (weights and biases) that minimize the error between the predicted output and the ground truth.

### Example
- Consider a simple linear model where `z = 2x`. 
- The cost function, denoted as `J(w)`, measures the difference between the predicted values and the actual values.
- The optimal value of `w` minimizes the cost function, which, in this example, is found to be `w = 2`.

---

## 2. Gradient Descent Algorithm

### Steps
1. **Initialization**: Start with a random value of `w` (e.g., `w = 0.2`).
2. **Calculate Gradient**: Compute the gradient of the cost function at the current value of `w`.
3. **Update Rule**: Update `w` using the formula: `w_new = w_old - (learning_rate * gradient)`.
4. **Iterate**: Repeat the process until convergence (i.e., the cost function is minimized).

### Key Points
- **Learning Rate**: Controls the size of the steps taken towards the minimum. A large learning rate may overshoot the minimum, while a small rate may slow down the process.
- **Convergence**: The algorithm stops when the cost function value changes very little between iterations.

---

## 3. Forward Propagation and Error Calculation

### Overview
- **Forward Propagation**: The process of making predictions using a neural network by passing inputs through the network layers.
- **Error Calculation**: The error `E` is calculated as the difference between the predicted values and the ground truth. This error serves as the basis for optimizing the network through backpropagation.

### Error Function
- Commonly used error function: **Mean Squared Error (MSE)**, calculated as the average of the squared differences between the predicted and actual values.

---

## 4. Backpropagation

### Overview
Backpropagation is the process of updating the weights and biases in a neural network by propagating the error backward through the network.

### Steps
1. **Calculate the Error**: Compute the error between the predicted output and the ground truth.
2. **Compute Gradients**: Use the chain rule to compute the gradient of the error with respect to each weight and bias.
3. **Update Weights and Biases**: Adjust the weights and biases using the gradients to reduce the error.

### Example
- For a simple two-neuron network, the weight `w2` is updated using the gradient:  
  `w2_new = w2_old - learning_rate * (∂E/∂w2)`
- Repeat the process for other weights (`w1`) and biases (`b1`, `b2`).

---

## 5. Vanishing Gradient Problem

### Overview
The vanishing gradient problem occurs when gradients become very small during backpropagation, especially in deep networks. This causes the earlier layers in the network to learn very slowly.

### Cause
- The **sigmoid activation function** is prone to this issue because it outputs values between 0 and 1. When multiplied repeatedly during backpropagation, these small values cause the gradient to diminish.

### Consequence
- Neurons in the earlier layers of the network are updated very slowly, leading to poor learning efficiency and longer training times.

---

## 6. Activation Functions

### Importance
Activation functions introduce non-linearity into the network, allowing it to learn complex patterns.

### Common Activation Functions
1. **Sigmoid Function**:
   - Formula: `σ(z) = 1 / (1 + e^(-z))`
   - Issues: Prone to the vanishing gradient problem; outputs are between 0 and 1.
  
2. **Hyperbolic Tangent (Tanh)**:
   - Formula: `tanh(z) = (e^z - e^(-z)) / (e^z + e^(-z))`
   - Outputs: Range from -1 to 1, helping to mitigate some issues with the sigmoid function.

3. **Rectified Linear Unit (ReLU)**:
   - Formula: `ReLU(z) = max(0, z)`
   - Advantage: Solves the vanishing gradient problem; widely used in deep networks.

4. **Leaky ReLU**:
   - Variation of ReLU that allows a small, non-zero gradient when the input is negative.

5. **Softmax Function**:
   - Used in the output layer of classification networks to convert logits into probabilities.

---

### Conclusion
Understanding gradient descent, backpropagation, and the role of activation functions is crucial for training neural networks effectively. Awareness of issues like the vanishing gradient problem informs the choice of activation functions, significantly impacting the performance and efficiency of deep learning models.

---
